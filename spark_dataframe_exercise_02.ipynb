{"cells":[{"cell_type":"markdown","source":["### titanic_train.csv 파일을 로드하고, 이를 DataFrame으로 변환"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"50f87cac-0a22-4a0c-a24e-e83757063089"}}},{"cell_type":"code","source":["#spark.read.csv() 메소드를 이용하여 csv 파일을 로드하고 DataFrame으로 변환. \n# pandas_df = pd.read_csv('/FileStore/tables/titanic_train.csv', header='infer')\ntitanic_sdf = spark.read.csv('/FileStore/tables/titanic_train.csv', header=True, inferSchema=True)\n\n# pandas DataFrame을 spark DataFrame으로 부터 생성. \ntitanic_pdf = titanic_sdf.select('*').toPandas()\n\ndisplay(titanic_sdf.limit(10))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19d39034-1d83-4d88-b9d7-d29ef5e3e8dc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[1,0,3,"Braund, Mr. Owen Harris","male",22.0,1,0,"A/5 21171",7.25,null,"S"],[2,1,1,"Cumings, Mrs. John Bradley (Florence Briggs Thayer)","female",38.0,1,0,"PC 17599",71.2833,"C85","C"],[3,1,3,"Heikkinen, Miss. Laina","female",26.0,0,0,"STON/O2. 3101282",7.925,null,"S"],[4,1,1,"Futrelle, Mrs. Jacques Heath (Lily May Peel)","female",35.0,1,0,"113803",53.1,"C123","S"],[5,0,3,"Allen, Mr. William Henry","male",35.0,0,0,"373450",8.05,null,"S"],[6,0,3,"Moran, Mr. James","male",null,0,0,"330877",8.4583,null,"Q"],[7,0,1,"McCarthy, Mr. Timothy J","male",54.0,0,0,"17463",51.8625,"E46","S"],[8,0,3,"Palsson, Master. Gosta Leonard","male",2.0,3,1,"349909",21.075,null,"S"],[9,1,3,"Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)","female",27.0,0,2,"347742",11.1333,null,"S"],[10,1,2,"Nasser, Mrs. Nicholas (Adele Achem)","female",14.0,1,0,"237736",30.0708,null,"C"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"PassengerId","type":"\"integer\"","metadata":"{}"},{"name":"Survived","type":"\"integer\"","metadata":"{}"},{"name":"Pclass","type":"\"integer\"","metadata":"{}"},{"name":"Name","type":"\"string\"","metadata":"{}"},{"name":"Sex","type":"\"string\"","metadata":"{}"},{"name":"Age","type":"\"double\"","metadata":"{}"},{"name":"SibSp","type":"\"integer\"","metadata":"{}"},{"name":"Parch","type":"\"integer\"","metadata":"{}"},{"name":"Ticket","type":"\"string\"","metadata":"{}"},{"name":"Fare","type":"\"double\"","metadata":"{}"},{"name":"Cabin","type":"\"string\"","metadata":"{}"},{"name":"Embarked","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>3</td><td>Braund, Mr. Owen Harris</td><td>male</td><td>22.0</td><td>1</td><td>0</td><td>A/5 21171</td><td>7.25</td><td>null</td><td>S</td></tr><tr><td>2</td><td>1</td><td>1</td><td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td><td>female</td><td>38.0</td><td>1</td><td>0</td><td>PC 17599</td><td>71.2833</td><td>C85</td><td>C</td></tr><tr><td>3</td><td>1</td><td>3</td><td>Heikkinen, Miss. Laina</td><td>female</td><td>26.0</td><td>0</td><td>0</td><td>STON/O2. 3101282</td><td>7.925</td><td>null</td><td>S</td></tr><tr><td>4</td><td>1</td><td>1</td><td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td><td>female</td><td>35.0</td><td>1</td><td>0</td><td>113803</td><td>53.1</td><td>C123</td><td>S</td></tr><tr><td>5</td><td>0</td><td>3</td><td>Allen, Mr. William Henry</td><td>male</td><td>35.0</td><td>0</td><td>0</td><td>373450</td><td>8.05</td><td>null</td><td>S</td></tr><tr><td>6</td><td>0</td><td>3</td><td>Moran, Mr. James</td><td>male</td><td>null</td><td>0</td><td>0</td><td>330877</td><td>8.4583</td><td>null</td><td>Q</td></tr><tr><td>7</td><td>0</td><td>1</td><td>McCarthy, Mr. Timothy J</td><td>male</td><td>54.0</td><td>0</td><td>0</td><td>17463</td><td>51.8625</td><td>E46</td><td>S</td></tr><tr><td>8</td><td>0</td><td>3</td><td>Palsson, Master. Gosta Leonard</td><td>male</td><td>2.0</td><td>3</td><td>1</td><td>349909</td><td>21.075</td><td>null</td><td>S</td></tr><tr><td>9</td><td>1</td><td>3</td><td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td><td>female</td><td>27.0</td><td>0</td><td>2</td><td>347742</td><td>11.1333</td><td>null</td><td>S</td></tr><tr><td>10</td><td>1</td><td>2</td><td>Nasser, Mrs. Nicholas (Adele Achem)</td><td>female</td><td>14.0</td><td>1</td><td>0</td><td>237736</td><td>30.0708</td><td>null</td><td>C</td></tr></tbody></table></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["titanic_sdf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c447f70-b56c-48ec-bcc4-aae6b80255fa"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### spark DataFrame의 orderBy() 알아보기\n* spark DataFrame의 orderBy() 메소드는 1개 이상의 컬럼순으로 정렬할 수 있는 기능. orderBy() 결과는 DataFrame으로 반환. \n* 정렬 컬럼은 문자열, 또는 컬럼 형태로 입력할 수 있으며, 정렬 컬럼이 여러개일 경우 개별 컬럼을 인자로 넣거나 list로도 넣을 수 있음. \n* 오름차순, 내림차순 구분은 ascending=True/False로 구분\n* 정렬 컬럼이 여러개 일때 개별 컬럼별로 서로 다른 정렬 옵션을 적용할 경우(예를 들어 컬럼1은 오름차순, 컬럼2는 내림차순) ascending=[True, False]와 같은 형태로 이용."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ce1f568b-f19d-435a-b5eb-f6e57466e657"}}},{"cell_type":"code","source":["# Name 컬럼으로 오름차순으로 정렬 \ntitanic_pdf_sorted_01 = titanic_pdf.sort_values(by=['Name'], ascending=True)\n\n# Pclass와 Name 컬럼으로 내림차순 정렬\ntitanic_pdf_sorted_02 = titanic_pdf.sort_values(by=['Pclass', 'Name'], ascending=False)\n\n# Pclass는 오름차순, Name은 내림차순 정렬\ntitanic_pdf_sorted_03 = titanic_pdf.sort_values(by=['Pclass', 'Name'], ascending=[True, False])\n\ndisplay(titanic_pdf_sorted_01)\ndisplay(titanic_pdf_sorted_02)\ndisplay(titanic_pdf_sorted_03)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2dbf9ab1-51b4-43ad-8f8b-4914b1b58a3f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import col \n\n# orderBy에 컬럼명을 문자열로 지정. \nprint(\"orderBy에 컬럼명을 문자열로 지정하고 내림 차순 정렬\")\ntitanic_sdf.orderBy(\"Name\", ascending=False).show() # select * from titanic_sdf order by Name desc\n\n# orderBy에 컬럼명을 컬럼형태로 지정.\nprint(\"orderBy에 컬럼명을 DataFrame['컬럼명'] 컬럼형태로 오름 차순 정렬\")\ntitanic_sdf.orderBy(titanic_sdf['Name'], ascending=True).show() # select * from titanic_sdf order by Name asc\n\nprint('orderBy에 컬럼명을 DataFrame.컬럼명 컬럼형태로 내림 차순 정렬')\ntitanic_sdf.orderBy(titanic_sdf.Name, ascending=False).show()\n\nprint(\"orderBy에 컬럼명을 col('컬럼명') 컬럼형태로 오름 차순 정렬\")\ntitanic_sdf.orderBy(col('Name'), ascending=True).show()\n\n# limit()를 이용해서 오름 차순으로 10개만 출력하고 싶다면?  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5a91d657-abe9-4d1d-a21b-3ccf876c7ff7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import col\n\nprint(\"orderBy에 여러개의 컬럼명을 문자열로 지정하고 내림 차순 정렬\")\ntitanic_sdf.orderBy(\"Pclass\", \"Name\", ascending=False).show() # select * from titanic_sdf order by Pclass desc, Name desc\ntitanic_sdf.orderBy([\"Pclass\", \"Name\"], ascending=False).show()\n\nprint(\"orderBy에 여러개의 컬럼명을 컬럼형태로 지정하고 내림 차순 정렬\")\ntitanic_sdf.orderBy(col(\"Pclass\"), col(\"Name\"), ascending=False).show()\n# Pclass는 오름차순, Name은 내림차순으로 정렬하고 싶다면 즉, select * from titanic_sdf order by Pclass asc, Name desc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80ecd92d-73a6-4c99-ba91-01b9f8529ed4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"orderBy에 여러개의 컬럼명을 문자열로 지정하고 내림 차순 정렬\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|        869|       0|     3|van Melkebeke, Mr...|  male|null|    0|    0|          345777|    9.5| null|       S|\n|        154|       0|     3|van Billiard, Mr....|  male|40.5|    0|    2|        A/5. 851|   14.5| null|       S|\n|        283|       0|     3|de Pelsmaeker, Mr...|  male|16.0|    0|    0|          345778|    9.5| null|       S|\n|        287|       1|     3|de Mulder, Mr. Th...|  male|30.0|    0|    0|          345774|    9.5| null|       S|\n|        560|       1|     3|de Messemaeker, M...|female|36.0|    1|    0|          345572|   17.4| null|       S|\n|        423|       0|     3|  Zimmerman, Mr. Leo|  male|29.0|    0|    0|          315082|  7.875| null|       S|\n|        241|       0|     3|Zabour, Miss. Tha...|female|null|    1|    0|            2665|14.4542| null|       C|\n|        112|       0|     3|Zabour, Miss. Hileni|female|14.5|    1|    0|            2665|14.4542| null|       C|\n|        496|       0|     3|Yousseff, Mr. Ger...|  male|null|    0|    0|            2627|14.4583| null|       C|\n|        355|       0|     3|   Yousif, Mr. Wazli|  male|null|    0|    0|            2647|  7.225| null|       C|\n|        204|       0|     3|Youseff, Mr. Gerious|  male|45.5|    0|    0|            2628|  7.225| null|       C|\n|        831|       1|     3|Yasbeck, Mrs. Ant...|female|15.0|    1|    0|            2659|14.4542| null|       C|\n|        621|       0|     3| Yasbeck, Mr. Antoni|  male|27.0|    1|    0|            2659|14.4542| null|       C|\n|        426|       0|     3|Wiseman, Mr. Phil...|  male|null|    0|    0|      A/4. 34244|   7.25| null|       S|\n|        492|       0|     3| Windelov, Mr. Einar|  male|21.0|    0|    0|SOTON/OQ 3101317|   7.25| null|       S|\n|        736|       0|     3|Williams, Mr. Leslie|  male|28.5|    0|    0|           54636|   16.1| null|       S|\n|        649|       0|     3|  Willey, Mr. Edward|  male|null|    0|    0|   S.O./P.P. 751|   7.55| null|       S|\n|        372|       0|     3|Wiklund, Mr. Jako...|  male|18.0|    1|    0|         3101267| 6.4958| null|       S|\n|        407|       0|     3|Widegren, Mr. Car...|  male|51.0|    0|    0|          347064|   7.75| null|       S|\n|        512|       0|     3|   Webber, Mr. James|  male|null|    0|    0|SOTON/OQ 3101316|   8.05| null|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|        869|       0|     3|van Melkebeke, Mr...|  male|null|    0|    0|          345777|    9.5| null|       S|\n|        154|       0|     3|van Billiard, Mr....|  male|40.5|    0|    2|        A/5. 851|   14.5| null|       S|\n|        283|       0|     3|de Pelsmaeker, Mr...|  male|16.0|    0|    0|          345778|    9.5| null|       S|\n|        287|       1|     3|de Mulder, Mr. Th...|  male|30.0|    0|    0|          345774|    9.5| null|       S|\n|        560|       1|     3|de Messemaeker, M...|female|36.0|    1|    0|          345572|   17.4| null|       S|\n|        423|       0|     3|  Zimmerman, Mr. Leo|  male|29.0|    0|    0|          315082|  7.875| null|       S|\n|        241|       0|     3|Zabour, Miss. Tha...|female|null|    1|    0|            2665|14.4542| null|       C|\n|        112|       0|     3|Zabour, Miss. Hileni|female|14.5|    1|    0|            2665|14.4542| null|       C|\n|        496|       0|     3|Yousseff, Mr. Ger...|  male|null|    0|    0|            2627|14.4583| null|       C|\n|        355|       0|     3|   Yousif, Mr. Wazli|  male|null|    0|    0|            2647|  7.225| null|       C|\n|        204|       0|     3|Youseff, Mr. Gerious|  male|45.5|    0|    0|            2628|  7.225| null|       C|\n|        831|       1|     3|Yasbeck, Mrs. Ant...|female|15.0|    1|    0|            2659|14.4542| null|       C|\n|        621|       0|     3| Yasbeck, Mr. Antoni|  male|27.0|    1|    0|            2659|14.4542| null|       C|\n|        426|       0|     3|Wiseman, Mr. Phil...|  male|null|    0|    0|      A/4. 34244|   7.25| null|       S|\n|        492|       0|     3| Windelov, Mr. Einar|  male|21.0|    0|    0|SOTON/OQ 3101317|   7.25| null|       S|\n|        736|       0|     3|Williams, Mr. Leslie|  male|28.5|    0|    0|           54636|   16.1| null|       S|\n|        649|       0|     3|  Willey, Mr. Edward|  male|null|    0|    0|   S.O./P.P. 751|   7.55| null|       S|\n|        372|       0|     3|Wiklund, Mr. Jako...|  male|18.0|    1|    0|         3101267| 6.4958| null|       S|\n|        407|       0|     3|Widegren, Mr. Car...|  male|51.0|    0|    0|          347064|   7.75| null|       S|\n|        512|       0|     3|   Webber, Mr. James|  male|null|    0|    0|SOTON/OQ 3101316|   8.05| null|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\norderBy에 여러개의 컬럼명을 컬럼형태로 지정하고 내림 차순 정렬\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|        869|       0|     3|van Melkebeke, Mr...|  male|null|    0|    0|          345777|    9.5| null|       S|\n|        154|       0|     3|van Billiard, Mr....|  male|40.5|    0|    2|        A/5. 851|   14.5| null|       S|\n|        283|       0|     3|de Pelsmaeker, Mr...|  male|16.0|    0|    0|          345778|    9.5| null|       S|\n|        287|       1|     3|de Mulder, Mr. Th...|  male|30.0|    0|    0|          345774|    9.5| null|       S|\n|        560|       1|     3|de Messemaeker, M...|female|36.0|    1|    0|          345572|   17.4| null|       S|\n|        423|       0|     3|  Zimmerman, Mr. Leo|  male|29.0|    0|    0|          315082|  7.875| null|       S|\n|        241|       0|     3|Zabour, Miss. Tha...|female|null|    1|    0|            2665|14.4542| null|       C|\n|        112|       0|     3|Zabour, Miss. Hileni|female|14.5|    1|    0|            2665|14.4542| null|       C|\n|        496|       0|     3|Yousseff, Mr. Ger...|  male|null|    0|    0|            2627|14.4583| null|       C|\n|        355|       0|     3|   Yousif, Mr. Wazli|  male|null|    0|    0|            2647|  7.225| null|       C|\n|        204|       0|     3|Youseff, Mr. Gerious|  male|45.5|    0|    0|            2628|  7.225| null|       C|\n|        831|       1|     3|Yasbeck, Mrs. Ant...|female|15.0|    1|    0|            2659|14.4542| null|       C|\n|        621|       0|     3| Yasbeck, Mr. Antoni|  male|27.0|    1|    0|            2659|14.4542| null|       C|\n|        426|       0|     3|Wiseman, Mr. Phil...|  male|null|    0|    0|      A/4. 34244|   7.25| null|       S|\n|        492|       0|     3| Windelov, Mr. Einar|  male|21.0|    0|    0|SOTON/OQ 3101317|   7.25| null|       S|\n|        736|       0|     3|Williams, Mr. Leslie|  male|28.5|    0|    0|           54636|   16.1| null|       S|\n|        649|       0|     3|  Willey, Mr. Edward|  male|null|    0|    0|   S.O./P.P. 751|   7.55| null|       S|\n|        372|       0|     3|Wiklund, Mr. Jako...|  male|18.0|    1|    0|         3101267| 6.4958| null|       S|\n|        407|       0|     3|Widegren, Mr. Car...|  male|51.0|    0|    0|          347064|   7.75| null|       S|\n|        512|       0|     3|   Webber, Mr. James|  male|null|    0|    0|SOTON/OQ 3101316|   8.05| null|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["orderBy에 여러개의 컬럼명을 문자열로 지정하고 내림 차순 정렬\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|        869|       0|     3|van Melkebeke, Mr...|  male|null|    0|    0|          345777|    9.5| null|       S|\n|        154|       0|     3|van Billiard, Mr....|  male|40.5|    0|    2|        A/5. 851|   14.5| null|       S|\n|        283|       0|     3|de Pelsmaeker, Mr...|  male|16.0|    0|    0|          345778|    9.5| null|       S|\n|        287|       1|     3|de Mulder, Mr. Th...|  male|30.0|    0|    0|          345774|    9.5| null|       S|\n|        560|       1|     3|de Messemaeker, M...|female|36.0|    1|    0|          345572|   17.4| null|       S|\n|        423|       0|     3|  Zimmerman, Mr. Leo|  male|29.0|    0|    0|          315082|  7.875| null|       S|\n|        241|       0|     3|Zabour, Miss. Tha...|female|null|    1|    0|            2665|14.4542| null|       C|\n|        112|       0|     3|Zabour, Miss. Hileni|female|14.5|    1|    0|            2665|14.4542| null|       C|\n|        496|       0|     3|Yousseff, Mr. Ger...|  male|null|    0|    0|            2627|14.4583| null|       C|\n|        355|       0|     3|   Yousif, Mr. Wazli|  male|null|    0|    0|            2647|  7.225| null|       C|\n|        204|       0|     3|Youseff, Mr. Gerious|  male|45.5|    0|    0|            2628|  7.225| null|       C|\n|        831|       1|     3|Yasbeck, Mrs. Ant...|female|15.0|    1|    0|            2659|14.4542| null|       C|\n|        621|       0|     3| Yasbeck, Mr. Antoni|  male|27.0|    1|    0|            2659|14.4542| null|       C|\n|        426|       0|     3|Wiseman, Mr. Phil...|  male|null|    0|    0|      A/4. 34244|   7.25| null|       S|\n|        492|       0|     3| Windelov, Mr. Einar|  male|21.0|    0|    0|SOTON/OQ 3101317|   7.25| null|       S|\n|        736|       0|     3|Williams, Mr. Leslie|  male|28.5|    0|    0|           54636|   16.1| null|       S|\n|        649|       0|     3|  Willey, Mr. Edward|  male|null|    0|    0|   S.O./P.P. 751|   7.55| null|       S|\n|        372|       0|     3|Wiklund, Mr. Jako...|  male|18.0|    1|    0|         3101267| 6.4958| null|       S|\n|        407|       0|     3|Widegren, Mr. Car...|  male|51.0|    0|    0|          347064|   7.75| null|       S|\n|        512|       0|     3|   Webber, Mr. James|  male|null|    0|    0|SOTON/OQ 3101316|   8.05| null|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|        869|       0|     3|van Melkebeke, Mr...|  male|null|    0|    0|          345777|    9.5| null|       S|\n|        154|       0|     3|van Billiard, Mr....|  male|40.5|    0|    2|        A/5. 851|   14.5| null|       S|\n|        283|       0|     3|de Pelsmaeker, Mr...|  male|16.0|    0|    0|          345778|    9.5| null|       S|\n|        287|       1|     3|de Mulder, Mr. Th...|  male|30.0|    0|    0|          345774|    9.5| null|       S|\n|        560|       1|     3|de Messemaeker, M...|female|36.0|    1|    0|          345572|   17.4| null|       S|\n|        423|       0|     3|  Zimmerman, Mr. Leo|  male|29.0|    0|    0|          315082|  7.875| null|       S|\n|        241|       0|     3|Zabour, Miss. Tha...|female|null|    1|    0|            2665|14.4542| null|       C|\n|        112|       0|     3|Zabour, Miss. Hileni|female|14.5|    1|    0|            2665|14.4542| null|       C|\n|        496|       0|     3|Yousseff, Mr. Ger...|  male|null|    0|    0|            2627|14.4583| null|       C|\n|        355|       0|     3|   Yousif, Mr. Wazli|  male|null|    0|    0|            2647|  7.225| null|       C|\n|        204|       0|     3|Youseff, Mr. Gerious|  male|45.5|    0|    0|            2628|  7.225| null|       C|\n|        831|       1|     3|Yasbeck, Mrs. Ant...|female|15.0|    1|    0|            2659|14.4542| null|       C|\n|        621|       0|     3| Yasbeck, Mr. Antoni|  male|27.0|    1|    0|            2659|14.4542| null|       C|\n|        426|       0|     3|Wiseman, Mr. Phil...|  male|null|    0|    0|      A/4. 34244|   7.25| null|       S|\n|        492|       0|     3| Windelov, Mr. Einar|  male|21.0|    0|    0|SOTON/OQ 3101317|   7.25| null|       S|\n|        736|       0|     3|Williams, Mr. Leslie|  male|28.5|    0|    0|           54636|   16.1| null|       S|\n|        649|       0|     3|  Willey, Mr. Edward|  male|null|    0|    0|   S.O./P.P. 751|   7.55| null|       S|\n|        372|       0|     3|Wiklund, Mr. Jako...|  male|18.0|    1|    0|         3101267| 6.4958| null|       S|\n|        407|       0|     3|Widegren, Mr. Car...|  male|51.0|    0|    0|          347064|   7.75| null|       S|\n|        512|       0|     3|   Webber, Mr. James|  male|null|    0|    0|SOTON/OQ 3101316|   8.05| null|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\norderBy에 여러개의 컬럼명을 컬럼형태로 지정하고 내림 차순 정렬\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|        869|       0|     3|van Melkebeke, Mr...|  male|null|    0|    0|          345777|    9.5| null|       S|\n|        154|       0|     3|van Billiard, Mr....|  male|40.5|    0|    2|        A/5. 851|   14.5| null|       S|\n|        283|       0|     3|de Pelsmaeker, Mr...|  male|16.0|    0|    0|          345778|    9.5| null|       S|\n|        287|       1|     3|de Mulder, Mr. Th...|  male|30.0|    0|    0|          345774|    9.5| null|       S|\n|        560|       1|     3|de Messemaeker, M...|female|36.0|    1|    0|          345572|   17.4| null|       S|\n|        423|       0|     3|  Zimmerman, Mr. Leo|  male|29.0|    0|    0|          315082|  7.875| null|       S|\n|        241|       0|     3|Zabour, Miss. Tha...|female|null|    1|    0|            2665|14.4542| null|       C|\n|        112|       0|     3|Zabour, Miss. Hileni|female|14.5|    1|    0|            2665|14.4542| null|       C|\n|        496|       0|     3|Yousseff, Mr. Ger...|  male|null|    0|    0|            2627|14.4583| null|       C|\n|        355|       0|     3|   Yousif, Mr. Wazli|  male|null|    0|    0|            2647|  7.225| null|       C|\n|        204|       0|     3|Youseff, Mr. Gerious|  male|45.5|    0|    0|            2628|  7.225| null|       C|\n|        831|       1|     3|Yasbeck, Mrs. Ant...|female|15.0|    1|    0|            2659|14.4542| null|       C|\n|        621|       0|     3| Yasbeck, Mr. Antoni|  male|27.0|    1|    0|            2659|14.4542| null|       C|\n|        426|       0|     3|Wiseman, Mr. Phil...|  male|null|    0|    0|      A/4. 34244|   7.25| null|       S|\n|        492|       0|     3| Windelov, Mr. Einar|  male|21.0|    0|    0|SOTON/OQ 3101317|   7.25| null|       S|\n|        736|       0|     3|Williams, Mr. Leslie|  male|28.5|    0|    0|           54636|   16.1| null|       S|\n|        649|       0|     3|  Willey, Mr. Edward|  male|null|    0|    0|   S.O./P.P. 751|   7.55| null|       S|\n|        372|       0|     3|Wiklund, Mr. Jako...|  male|18.0|    1|    0|         3101267| 6.4958| null|       S|\n|        407|       0|     3|Widegren, Mr. Car...|  male|51.0|    0|    0|          347064|   7.75| null|       S|\n|        512|       0|     3|   Webber, Mr. James|  male|null|    0|    0|SOTON/OQ 3101316|   8.05| null|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# orderBy에 여러개의 컬럼명을 지정하고 서로 다른 방식으로 정렬하기\nfrom pyspark.sql.functions import col \n\nprint(\"orderBy에 여러개의 컬럼명을 문자열로 지정하고 서로 다른 방식으로 정렬 \")\ntitanic_sdf.orderBy('Pclass', 'Name', ascending=[True, False]).show()\n\n\nprint(\"orderBy에 여러개의 컬럼명을 컬럼형태로 지정하고 서로 다른 방식으로 정렬 \")\ntitanic_sdf.orderBy(col('Pclass'), col('Name'), ascending=[True, False]).show()\n\n# 개별 컬럼별로 asc(), desc()를 적용. \ntitanic_sdf.orderBy(col('Pclass').asc(), col('Name').desc()).show() # select * from titanic_sdf order by Pclass asc, Name desc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9b26357-a7cd-4446-a87e-2b68570b7ce3"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# orderBy()와 동일한 메소드로 sort()를 제공. \ntitanic_sdf.sort(col('Pclass').asc(), col('Name').desc()).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b31e473b-b4a8-4b9d-b8c0-3cb97d87f221"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# select Pclass, Name from titanic_sdf order by Pclass asc, Name desc\ntitanic_sdf.select(col('Pclass'), col('Name')).orderBy(col('Pclass').asc(), col('Name').desc()).show() \n\n#select Pclass, Name from (select * from titanic_sdf order by Pclass asc, Name desc)\ntitanic_sdf.orderBy(col('Pclass').asc(), col('Name').desc()).select(col('Pclass'), col('Name')).show() # \n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31ecf105-1466-4096-96fa-1398aa19e876"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### spark DataFrame에 aggregation 메소드 적용하기\n* pandas DataFrame은 DataFrame 객체에서 aggregation 메소드를 많이 가질 수 있음(DataFrame.count(), DataFrame.max())\n* pandas DataFrame은 DataFrame 객체에 aggregation 메소드를 적용 시 DataFrame에 속한 전체 컬럼들에 모두 aggregation 메소드를 적용\n* spark DataFrame은 DataFrame 객체에서 aggregation 메소드를 별로 가지고 있지 않음. count() 메소드 정도... \n* spark DataFrame에 aggregation 메소드를 적용 시에는 pyspark.sql.functions 모듈의 max, min, sum 등의 함수를 이용해야함."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef290b40-8c5d-42fa-834b-1dedbf22e778"}}},{"cell_type":"code","source":["print('#### pandas dataframe count() aggregation ####')\nprint(titanic_pdf.count())\n\nprint('#### pandas dataframe max() aggregation ####')\nprint(titanic_pdf.max())\n\nprint('#### pandas dataframe count() aggregation 결과 type ####')\nprint(type(titanic_pdf.count()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"95dbf9d1-53c2-43b7-a1d6-b886c061891e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print(titanic_pdf[['Pclass', 'Age']].max())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db0695b2-21e0-491c-a532-4e1c2c9a0816"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# spark DataFrame에 count() aggregation을 적용하면 DataFrame의 Record 건수 반환. \nprint('count 결과:', titanic_sdf.count()) # select count(*) from titanic_sdf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fb81bbca-e58a-4050-9826-3d94f92fec17"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# 하지만 count() 가 아닌 다른 aggregation 함수를 DataFrame에 적용하면 오류 발생.이는 SQL과 유사\n# 이는 count() aggregation 함수가 가진 특수성. 다른 aggregation 함수들은 어떤 컬럼을 aggregation 할지 명시해줘야 함. \n# count()외의 다른 aggregation 함수, 예를 들어 max(), min()등은 pyspark.sql.functions 모듈에 별도로 구현되어 있음. \ntitanic_sdf.max() # select max() from titanic_sdf 와 같은 SQL을 구문 오류. "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6a033ff-dd6c-48d1-8d78-35b07a01720c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import max, sum, min\n\n# spark DataFrame에 count()를 제외하고 max(), min(), sum(), avg()와 같은 aggregate 메소드를 바로 호출할 수 없으며, select()메소드 내에서 호출되어야 함. \ntitanic_sdf_max = titanic_sdf.select(max('Age')) # select max(Age) from titanic_sdf\nprint(titanic_sdf_max.show())\nprint(type(titanic_sdf_max)) # max() aggregation은 단 한개의 값을 반환하지만 DataFrame으로 반환. "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5365bd0-1cc8-4be1-9d33-e0ede2e374aa"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### spark DataFrame의 groupBy() 알아 보기\n* pandas DataFrame의 groupby(by='group_by_컬럼명') 수행 시 group_by_컬럼명 레벨로 group by 된 DataFrameGroupBy 객체 반환하고 여기에 aggregation 메소드 적용. \n* spark DataFrame도 groupBy('group_by_컬럼명') 수행 시 group_by_컬럼명 레벨로 group by 된 GroupedData 객체 반환하고 여기에 aggregation 메소드 적용.\n* pandas DataFrameGroupBy 객체에 agg() 메소드를 이용하여 서로 다른 컬럼에 서로 다른 aggregation 함수 적용 가능\n* spark GroupedData 객체도 agg() 메소드를 이용하여 서로 다른 컬럼에 서로 다른 aggregation 함수 적용 가능\n* spark groupBy()는 pandas groupby()의 특징과 SQL의 특징을 함께 가짐."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"315c3200-fd0d-470b-a9da-acb1c55d69a1"}}},{"cell_type":"code","source":["# pandas DataFrame에 groupby()메소드 호출 시 DataFrameGroupBy 객체 반환. \ntitanic_pdf_groupby = titanic_pdf.groupby(by='Pclass')\nprint('pandas DataFrame의 groupby() 적용 결과 type:', type(titanic_pdf_groupby))\n\n# Group by 된 pandas DataFrameGroupBy 객체에 count()를 적용 시 group by 된 컬럼값 레벨로 모든 컬럼들의 count() 수행. \nprint('\\n#### group by 레벨로 모든 컬럼에 count 적용 #### ')\nprint(titanic_pdf.groupby(by='Pclass').count())\n\nprint('\\n#### group by 레벨로 특정 컬럼에 aggregation 적용 #### ')\n# Group by 된 pandas DataFrameGroupBy 객체에 특정 컬럼에 aggregation 을 적용하려면 해당 컬럼을 ['컬럼명'] 추출하여 aggregation 함수 적용. \nprint(titanic_pdf.groupby(by='Pclass')['Age'].max()) # select max(Age) from titanic_pdf group by Pclass\n\n# pandas DataFrameGroupBy 객체에 여러 컬럼에 동일 aggregation 을 적용하려면 해당 컬럼들을 [['컬럼명1', '컬럼명2']]로 추출하여 aggregation 함수 적용. \nprint('\\n####  group by 레벨로 여러 컬럼에 동일 aggregation 적용 #### ')\nprint(titanic_pdf.groupby(by='Pclass')[['Age', 'Fare']].max()) # select max(Age), max(Fare) from titanic_pdf group by Pclass\n\n# Group by 된 DataFrameGroupBy 객체에 서로 다른 컬럼에 서로 다른 aggregation 함수를 적용하려면 agg() 메소드를 사용. \n# agg()메소드 내부에 인자는 dictionary 형태로 적용 컬럼명과 적용 aggregation 함수 기재\nprint('\\n####  group by 레벨로 여러개의 aggregation 함수를 서로 다른 컬럼에 적용 #### ')\nagg_format = {'Age':'max', 'SibSp':'sum', 'Fare':'mean'}\nprint(titanic_pdf.groupby(by='Pclass').agg(agg_format))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71b673b8-bab8-4375-a1eb-2d9cefdc3c52"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"pandas DataFrame의 groupby() 적용 결과 type: <class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n\n#### group by 레벨로 모든 컬럼에 count 적용 #### \n        PassengerId  Survived  Name  Sex  ...  Ticket  Fare  Cabin  Embarked\nPclass                                    ...                               \n1               216       216   216  216  ...     216   216    176       214\n2               184       184   184  184  ...     184   184     16       184\n3               491       491   491  491  ...     491   491     12       491\n\n[3 rows x 11 columns]\n\n#### group by 레벨로 특정 컬럼에 aggregation 적용 #### \nPclass\n1    80.0\n2    70.0\n3    74.0\nName: Age, dtype: float64\n\n####  group by 레벨로 여러 컬럼에 동일 aggregation 적용 #### \n         Age      Fare\nPclass                \n1       80.0  512.3292\n2       70.0   73.5000\n3       74.0   69.5500\n\n####  group by 레벨로 여러개의 aggregation 함수를 서로 다른 컬럼에 적용 #### \n         Age  SibSp       Fare\nPclass                        \n1       80.0     90  84.154687\n2       70.0     74  20.662183\n3       74.0    302  13.675550\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["pandas DataFrame의 groupby() 적용 결과 type: <class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n\n#### group by 레벨로 모든 컬럼에 count 적용 #### \n        PassengerId  Survived  Name  Sex  ...  Ticket  Fare  Cabin  Embarked\nPclass                                    ...                               \n1               216       216   216  216  ...     216   216    176       214\n2               184       184   184  184  ...     184   184     16       184\n3               491       491   491  491  ...     491   491     12       491\n\n[3 rows x 11 columns]\n\n#### group by 레벨로 특정 컬럼에 aggregation 적용 #### \nPclass\n1    80.0\n2    70.0\n3    74.0\nName: Age, dtype: float64\n\n####  group by 레벨로 여러 컬럼에 동일 aggregation 적용 #### \n         Age      Fare\nPclass                \n1       80.0  512.3292\n2       70.0   73.5000\n3       74.0   69.5500\n\n####  group by 레벨로 여러개의 aggregation 함수를 서로 다른 컬럼에 적용 #### \n         Age  SibSp       Fare\nPclass                        \n1       80.0     90  84.154687\n2       70.0     74  20.662183\n3       74.0    302  13.675550\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# pandas DataFrame의 value_counts()는 Series에 적용시 해당 series내의 값 별로 건수를 구함. \nprint(titanic_pdf['Pclass'].value_counts())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f53d6fe7-59c0-4819-ae00-b887707f32fc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"3    491\n1    216\n2    184\nName: Pclass, dtype: int64\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["3    491\n1    216\n2    184\nName: Pclass, dtype: int64\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# pandas 의 value_counts()의 대응될 수 있는 groupBy() 메소드. Spark DataFrame에 groupBy() 적용 시 GroupedData Object 반환.\n# GroupedData Object에 count()외에 min(), max(), avg(), sum() 등 다양한 aggregation 메소드를 호출하여 group by, aggregation 결과 DataFrame 반환. \ntitanic_sdf.groupBy('Pclass').count().show() # select pclass, count(*) from titanic_sdf group by pclass\n\nprint('spark DataFrame groupBy type:', type(titanic_sdf.groupBy('Pclass')))\nprint('spark GroupedData의 aggregation 메소드 적용 결과 type:', titanic_sdf.groupBy('Pclass').count()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"10e61da0-62de-4adc-9c33-20b32c1da75b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------+-----+\n|Pclass|count|\n+------+-----+\n|     1|  216|\n|     3|  491|\n|     2|  184|\n+------+-----+\n\nspark DataFrame groupBy type: <class 'pyspark.sql.group.GroupedData'>\nspark GroupedData의 aggregation 메소드 적용 결과 type: DataFrame[Pclass: int, count: bigint]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+-----+\n|Pclass|count|\n+------+-----+\n|     1|  216|\n|     3|  491|\n|     2|  184|\n+------+-----+\n\nspark DataFrame groupBy type: <class 'pyspark.sql.group.GroupedData'>\nspark GroupedData의 aggregation 메소드 적용 결과 type: DataFrame[Pclass: int, count: bigint]\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# spark DataFrame의 orderBy()메소드를 적용하여 group by 결과 건수 descending 으로 정렬 \ntitanic_sdf.groupBy('Pclass').count().orderBy('count', ascending=False).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f65c1b00-007c-4365-9b2a-4430b5afa274"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------+-----+\n|Pclass|count|\n+------+-----+\n|     3|  491|\n|     1|  216|\n|     2|  184|\n+------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+-----+\n|Pclass|count|\n+------+-----+\n|     3|  491|\n|     1|  216|\n|     2|  184|\n+------+-----+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["#GroupedData 에 count()가 아니고 다른 aggregation 메소드를 적용 시 pandas DataFrame의 groupby와 유사하게 group by된 컬럼 레벨로 전체 컬럼에 대해서 aggregation을 적용. \ntitanic_sdf.groupBy('Pclass').max().show() "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d5f42d0-b263-4ecc-bf35-b268e5b8225c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------+----------------+-------------+-----------+--------+----------+----------+---------+\n|Pclass|max(PassengerId)|max(Survived)|max(Pclass)|max(Age)|max(SibSp)|max(Parch)|max(Fare)|\n+------+----------------+-------------+-----------+--------+----------+----------+---------+\n|     1|             890|            1|          1|    80.0|         3|         4| 512.3292|\n|     3|             891|            1|          3|    74.0|         8|         6|    69.55|\n|     2|             887|            1|          2|    70.0|         3|         3|     73.5|\n+------+----------------+-------------+-----------+--------+----------+----------+---------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+----------------+-------------+-----------+--------+----------+----------+---------+\n|Pclass|max(PassengerId)|max(Survived)|max(Pclass)|max(Age)|max(SibSp)|max(Parch)|max(Fare)|\n+------+----------------+-------------+-----------+--------+----------+----------+---------+\n|     1|             890|            1|          1|    80.0|         3|         4| 512.3292|\n|     3|             891|            1|          3|    74.0|         8|         6|    69.55|\n|     2|             887|            1|          2|    70.0|         3|         3|     73.5|\n+------+----------------+-------------+-----------+--------+----------+----------+---------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# group by 레벨로 특정 컬럼에 aggregation 적용. max('컬럼명')과 같이 aggregation 메소드 내부에 인자로 컬러명 입력\ntitanic_sdf.groupBy('Pclass').max('Age').show() # select max(Age) from titainic_sdf group by Pclass\n\n#GroupedData에서 aggregation 메소드 호출 시 오직 문자열 컬럼명만 가능. 컬럼형 인자 입력은 오류 발생. \ntitanic_sdf.groupBy('Pclass').max(col('Age')).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b32c6259-96c0-430c-b2dc-bba714cf788b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------+--------+\n|Pclass|max(Age)|\n+------+--------+\n|     1|    80.0|\n|     3|    74.0|\n|     2|    70.0|\n+------+--------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+--------+\n|Pclass|max(Age)|\n+------+--------+\n|     1|    80.0|\n|     3|    74.0|\n|     2|    70.0|\n+------+--------+\n\n"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-1567257586276313>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#GroupedData에서 aggregation 메소드 호출 시 오직 문자열 컬럼명만 가능. 컬럼형 인자 입력은 오류 발생.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mtitanic_sdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroupBy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Pclass'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Age'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/group.py\u001B[0m in \u001B[0;36m_api\u001B[0;34m(self, *cols)\u001B[0m\n\u001B[1;32m     39\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_api\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mcols\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0mname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m         \u001B[0mjdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jgd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_to_seq\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcols\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql_ctx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m     \u001B[0m_api\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/column.py\u001B[0m in \u001B[0;36m_to_seq\u001B[0;34m(sc, cols, converter)\u001B[0m\n\u001B[1;32m     61\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mconverter\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m         \u001B[0mcols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mconverter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcols\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0msc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jvm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPythonUtils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoSeq\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcols\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1294\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1295\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1296\u001B[0;31m         \u001B[0margs_command\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_build_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1298\u001B[0m         \u001B[0mcommand\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mproto\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCALL_COMMAND_NAME\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m_build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1258\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_build_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1259\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1260\u001B[0;31m             \u001B[0;34m(\u001B[0m\u001B[0mnew_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1261\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1262\u001B[0m             \u001B[0mnew_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m_get_args\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m   1245\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mconverter\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1246\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mconverter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcan_convert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1247\u001B[0;31m                         \u001B[0mtemp_arg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconverter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1248\u001B[0m                         \u001B[0mtemp_args\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtemp_arg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1249\u001B[0m                         \u001B[0mnew_args\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtemp_arg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_collections.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n\u001B[1;32m    509\u001B[0m         \u001B[0mjava_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mArrayList\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    510\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0melement\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 511\u001B[0;31m             \u001B[0mjava_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0melement\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    512\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mjava_list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    513\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1294\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1295\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1296\u001B[0;31m         \u001B[0margs_command\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_build_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1298\u001B[0m         \u001B[0mcommand\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mproto\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCALL_COMMAND_NAME\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m_build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1258\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_build_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1259\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1260\u001B[0;31m             \u001B[0;34m(\u001B[0m\u001B[0mnew_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1261\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1262\u001B[0m             \u001B[0mnew_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m_get_args\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m   1245\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mconverter\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1246\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mconverter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcan_convert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1247\u001B[0;31m                         \u001B[0mtemp_arg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconverter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1248\u001B[0m                         \u001B[0mtemp_args\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtemp_arg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1249\u001B[0m                         \u001B[0mnew_args\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtemp_arg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_collections.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n\u001B[1;32m    508\u001B[0m         \u001B[0mArrayList\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mJavaClass\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"java.util.ArrayList\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    509\u001B[0m         \u001B[0mjava_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mArrayList\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 510\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0melement\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    511\u001B[0m             \u001B[0mjava_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0melement\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    512\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mjava_list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/column.py\u001B[0m in \u001B[0;36m__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    470\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    471\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__iter__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 472\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Column is not iterable\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    473\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    474\u001B[0m     \u001B[0;31m# string methods\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mTypeError\u001B[0m: Column is not iterable","errorSummary":"<span class='ansi-red-fg'>TypeError</span>: Column is not iterable","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-1567257586276313>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#GroupedData에서 aggregation 메소드 호출 시 오직 문자열 컬럼명만 가능. 컬럼형 인자 입력은 오류 발생.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mtitanic_sdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroupBy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Pclass'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Age'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/group.py\u001B[0m in \u001B[0;36m_api\u001B[0;34m(self, *cols)\u001B[0m\n\u001B[1;32m     39\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_api\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mcols\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0mname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m         \u001B[0mjdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jgd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_to_seq\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcols\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql_ctx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m     \u001B[0m_api\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/column.py\u001B[0m in \u001B[0;36m_to_seq\u001B[0;34m(sc, cols, converter)\u001B[0m\n\u001B[1;32m     61\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mconverter\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m         \u001B[0mcols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mconverter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcols\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0msc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jvm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPythonUtils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoSeq\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcols\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1294\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1295\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1296\u001B[0;31m         \u001B[0margs_command\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_build_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1298\u001B[0m         \u001B[0mcommand\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mproto\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCALL_COMMAND_NAME\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m_build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1258\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_build_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1259\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1260\u001B[0;31m             \u001B[0;34m(\u001B[0m\u001B[0mnew_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1261\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1262\u001B[0m             \u001B[0mnew_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m_get_args\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m   1245\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mconverter\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1246\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mconverter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcan_convert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1247\u001B[0;31m                         \u001B[0mtemp_arg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconverter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1248\u001B[0m                         \u001B[0mtemp_args\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtemp_arg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1249\u001B[0m                         \u001B[0mnew_args\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtemp_arg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_collections.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n\u001B[1;32m    509\u001B[0m         \u001B[0mjava_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mArrayList\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    510\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0melement\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 511\u001B[0;31m             \u001B[0mjava_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0melement\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    512\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mjava_list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    513\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1294\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1295\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1296\u001B[0;31m         \u001B[0margs_command\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_build_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1298\u001B[0m         \u001B[0mcommand\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mproto\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCALL_COMMAND_NAME\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m_build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1258\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_build_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1259\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1260\u001B[0;31m             \u001B[0;34m(\u001B[0m\u001B[0mnew_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1261\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1262\u001B[0m             \u001B[0mnew_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m_get_args\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m   1245\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mconverter\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1246\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mconverter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcan_convert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1247\u001B[0;31m                         \u001B[0mtemp_arg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconverter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1248\u001B[0m                         \u001B[0mtemp_args\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtemp_arg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1249\u001B[0m                         \u001B[0mnew_args\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtemp_arg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_collections.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n\u001B[1;32m    508\u001B[0m         \u001B[0mArrayList\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mJavaClass\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"java.util.ArrayList\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    509\u001B[0m         \u001B[0mjava_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mArrayList\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 510\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0melement\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    511\u001B[0m             \u001B[0mjava_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0melement\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    512\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mjava_list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/column.py\u001B[0m in \u001B[0;36m__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    470\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    471\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__iter__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 472\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Column is not iterable\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    473\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    474\u001B[0m     \u001B[0;31m# string methods\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mTypeError\u001B[0m: Column is not iterable"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# 여러 컬럼으로 Group by 규정할 때 개별 컬럼명을 입력하거나, list 형태로 입력 가능. \ntitanic_sdf.groupBy('Pclass', 'Sex').max('Age').show() # select max(Age) from titanic_sdf group by Pclass, Sex\ntitanic_sdf.groupBy(['Pclass', 'Sex']).max('Age').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e0ef6dac-a053-4b93-8889-ab9a6d3e797e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------+------+--------+\n|Pclass|   Sex|max(Age)|\n+------+------+--------+\n|     2|female|    57.0|\n|     3|  male|    74.0|\n|     1|  male|    80.0|\n|     3|female|    63.0|\n|     1|female|    63.0|\n|     2|  male|    70.0|\n+------+------+--------+\n\n+------+------+--------+\n|Pclass|   Sex|max(Age)|\n+------+------+--------+\n|     2|female|    57.0|\n|     3|  male|    74.0|\n|     1|  male|    80.0|\n|     3|female|    63.0|\n|     1|female|    63.0|\n|     2|  male|    70.0|\n+------+------+--------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+------+--------+\n|Pclass|   Sex|max(Age)|\n+------+------+--------+\n|     2|female|    57.0|\n|     3|  male|    74.0|\n|     1|  male|    80.0|\n|     3|female|    63.0|\n|     1|female|    63.0|\n|     2|  male|    70.0|\n+------+------+--------+\n\n+------+------+--------+\n|Pclass|   Sex|max(Age)|\n+------+------+--------+\n|     2|female|    57.0|\n|     3|  male|    74.0|\n|     1|  male|    80.0|\n|     3|female|    63.0|\n|     1|female|    63.0|\n|     2|  male|    70.0|\n+------+------+--------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["### 여러개의 aggregation 함수를 적용할 경우는 agg()메소드 내에서 개별 aggregation 함수를 명시 해야함. \n\nfrom pyspark.sql.functions import max, avg, sum, min\n\n# select max(age), min(age), sum(age), avg(age) from titanic_sdf group by pclass\ntitanic_sdf.groupBy('Pclass').agg(max('Age'), min('Age'), sum('Age'), avg('Age')).show() # select max(age), min(age), sum(age), avg(age) from titanic_sdf group by pclass"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03583243-8276-4e6c-baa6-0967af4f7633"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------+--------+--------+--------+------------------+\n|Pclass|max(Age)|min(Age)|sum(Age)|          avg(Age)|\n+------+--------+--------+--------+------------------+\n|     1|    80.0|    0.92| 7111.42|38.233440860215055|\n|     3|    74.0|    0.42| 8924.92| 25.14061971830986|\n|     2|    70.0|    0.67| 5168.83| 29.87763005780347|\n+------+--------+--------+--------+------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+--------+--------+--------+------------------+\n|Pclass|max(Age)|min(Age)|sum(Age)|          avg(Age)|\n+------+--------+--------+--------+------------------+\n|     1|    80.0|    0.92| 7111.42|38.233440860215055|\n|     3|    74.0|    0.42| 8924.92| 25.14061971830986|\n|     2|    70.0|    0.67| 5168.83| 29.87763005780347|\n+------+--------+--------+--------+------------------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["#아래와 같이 개별 aggregation 함수 결과 컬럼에 별도의 컬럼명을 alias('새로운 컬럼명')을 활용하여 부여 할 수 있음. \n# agg() 메소드 내에서 aggregation 함수 적용 시에는 col('컬럼명')과 같은 컬럼형으로 컬럼명을 지정해도 됨. \n# select max(age) as max_age, min(age) as min_age, sum(age) as sum_age, avg(age) as avg_age from titanic_sdf group by pclass\ntitanic_sdf.groupBy('Pclass').agg(\n    max(col('Age')).alias('max_age'), min('Age').alias('min_age'), \\\n    sum('Age').alias('sum_age'), avg('Age').alias('avg_age') \\\n    ).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0832809a-0816-4cb3-b55d-72d0d3f08847"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------+-------+-------+-------+------------------+\n|Pclass|max_age|min_age|sum_age|           avg_age|\n+------+-------+-------+-------+------------------+\n|     1|   80.0|   0.92|7111.42|38.233440860215055|\n|     3|   74.0|   0.42|8924.92| 25.14061971830986|\n|     2|   70.0|   0.67|5168.83| 29.87763005780347|\n+------+-------+-------+-------+------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+-------+-------+-------+------------------+\n|Pclass|max_age|min_age|sum_age|           avg_age|\n+------+-------+-------+-------+------------------+\n|     1|   80.0|   0.92|7111.42|38.233440860215055|\n|     3|   74.0|   0.42|8924.92| 25.14061971830986|\n|     2|   70.0|   0.67|5168.83| 29.87763005780347|\n+------+-------+-------+-------+------------------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# 아래와 같이 filter()를 적용하여 group by의 aggregation 결과 값을 기준으로 filtering 적용할 수 있음. \n'''\nselect max(age) as max_age, min(age) as min_age, sum(age) as sum_age, avg(age) as avg_age from titanic_sdf group by pclass having max(age) > 70\n또는 \nselect max_age, min_age, sum_avg, avg_age \nfrom (\n      select max(age) as max_age, min(age) as min_age, sum(age) as sum_age, avg(age) as avg_age from titanic_sdf group by pclass\n) where max_age > 70\n'''\ntitanic_sdf.groupBy('Pclass').agg(max(col('Age')).alias('max_age'), min('Age').alias('min_age') , \\\n                                 sum('Age').alias('sum_age'), avg('Age').alias('avg_age') \\\n                                 ).filter(col('max_age') > 70).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"acef7ad8-971d-4b38-a4c6-7f62dbd4c2e6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------+-------+-------+-------+------------------+\n|Pclass|max_age|min_age|sum_age|           avg_age|\n+------+-------+-------+-------+------------------+\n|     1|   80.0|   0.92|7111.42|38.233440860215055|\n|     3|   74.0|   0.42|8924.92| 25.14061971830986|\n+------+-------+-------+-------+------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+-------+-------+-------+------------------+\n|Pclass|max_age|min_age|sum_age|           avg_age|\n+------+-------+-------+-------+------------------+\n|     1|   80.0|   0.92|7111.42|38.233440860215055|\n|     3|   74.0|   0.42|8924.92| 25.14061971830986|\n+------+-------+-------+-------+------------------+\n\n"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"spark_dataframe_exercise_02 (1)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1567257586276291}},"nbformat":4,"nbformat_minor":0}
